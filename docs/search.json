[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Code Blog",
    "section": "",
    "text": "Building a Technical Trading Data & Analytics Pipeline\n\n\n\n\n\n\nR\n\n\nPython\n\n\nInvesting\n\n\n\nThis post is the first in a series chronicling a personal project: setting up a technical investment data and analytics pipeline with Python and R\n\n\n\n\n\nApr 1, 2025\n\n\nLance Couzens\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding and Working with a List of ggplot Objects in R\n\n\n\n\n\n\nR\n\n\nGraphics\n\n\nLists\n\n\nCensus API\n\n\n\nHere we make a list of choropleth maps\n\n\n\n\n\nMar 22, 2025\n\n\nLance Couzens\n\n\n\n\n\n\n\n\n\n\n\n\nDecoupling Dynamic Code from a Static R Codebase\n\n\n\n\n\n\nR\n\n\nQuality\n\n\n\nHere we look at 2 ways to isolate the code that may change from the code that doesn’t need to\n\n\n\n\n\nMar 20, 2025\n\n\nLance Couzens\n\n\n\n\n\n\n\n\n\n\n\n\nR vs. Python Query Compute Time Example\n\n\n\n\n\n\nR\n\n\nPython\n\n\n\nHere we compare runtime to query a large csv in R and Python\n\n\n\n\n\nMar 19, 2025\n\n\nLance Couzens\n\n\n\n\n\n\n\n\n\n\n\n\nRecreating Some Tidy-Style R Operations with Python and Polars\n\n\n\n\n\n\nR\n\n\nPython\n\n\n\nThis post lays out a series of examples that helped me break into Python as a Tidy-style R programmer\n\n\n\n\n\nMar 19, 2025\n\n\nLance Couzens\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lance Couzens",
    "section": "",
    "text": "Hello, and welcome to my code-stuff website. I’m a statistician/data professional who is very interested in totally obsessed with open-source programming. Most of the action is happening under the Code Blog. Thanks for stopping by, and don’t hesitate to hit me up via email if you’d like to chat about coding, statistics, photography, or… whatever."
  },
  {
    "objectID": "posts/2025-03-22-Choropleths-and-LIst-Retrieval-Fun/index.html",
    "href": "posts/2025-03-22-Choropleths-and-LIst-Retrieval-Fun/index.html",
    "title": "Building and Working with a List of ggplot Objects in R",
    "section": "",
    "text": "Lists are, in many ways, R’s most powerful objects. They are vectors without type, general and flexible. You can fill them with anything—including other lists—and while this enables some truly useful complexity in our R-based processes, it can also make creating and working with lists daunting, especially for newer R programmers.\nWith this post I make no attempt to explain (let alone fully explain) lists in R. Instead I just hope to showcase one example of doing something fun (and maybe kinda useful-ish?) with them: storing and retrieving income disparity choropleth maps made with the Census API and ggplot2. Everyone loves maps, right?!\nHere’s what we’ll do:\n\nretrieve a state-level data frame with 2023 ACS 5-year poverty estimates via the Census API\ncreate the recode variable prop_below that represents the proportion of the state population with household income below the poverty limit\nsort in descending order by prop_below\nusing the resulting data frame as a parameter file, iterate a custom function that\n\nretrieves county-level median income estimates and polygons for a given state via the Census API\nranks the counties by their median income\ngenerates clean labels for the top and bottom counties\ncreates a plot object containing the county choropleth map for the state\nreturns a list containing the plot, the state abbreviation, and the state name\n\n\nAt this point, we will have a list with 50 elements—one for each state—each of which is a list containing the state-level plots plus state names and abbreviations. We will explore three ways to extract plots from this list.\nFirst, we’ll load the necessary libraries and create our state-level parameter file.\n\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(ggplot2)\nlibrary(scales)\n\nyear&lt;-2023\n\npoverty_data&lt;-get_acs(\n  geography=\"state\"\n  ,variables=c(\n      below_p5pov=\"C17002_002\"\n      ,p5_1pov=\"C17002_003\"\n      ,total_population=\"C17002_001\"\n  )\n  ,year=year\n  ,survey=\"acs5\"\n) %&gt;%\n  pivot_wider(\n    id_cols=c(GEOID,NAME)\n    ,names_from=\"variable\"\n    ,values_from=\"estimate\"\n  ) %&gt;%\n  filter(!GEOID %in% c(72,11)) %&gt;%\n  mutate(\n    prop_below=(below_p5pov+p5_1pov)/total_population\n    ,year=.env$year\n  ) %&gt;%\n  arrange(desc(prop_below))\n\nLet’s look at the parameter file to see what our functional process has to work with.\n\npoverty_data\n\n# A tibble: 50 × 7\n   GEOID NAME           total_population below_p5pov p5_1pov prop_below  year\n   &lt;chr&gt; &lt;chr&gt;                     &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 28    Mississippi             2851847      244374  299323      0.191  2023\n 2 22    Louisiana               4494539      390425  458344      0.189  2023\n 3 35    New Mexico              2073857      174355  201026      0.181  2023\n 4 54    West Virginia           1728580      131400  156260      0.166  2023\n 5 21    Kentucky                4382816      325901  381579      0.161  2023\n 6 05    Arkansas                2944742      209434  262349      0.160  2023\n 7 01    Alabama                 4913932      352821  415364      0.156  2023\n 8 40    Oklahoma                3872738      276048  317772      0.153  2023\n 9 45    South Carolina          5072217      340381  379339      0.142  2023\n10 48    Texas                  29016925     1845809 2159608      0.138  2023\n# ℹ 40 more rows\n\n\nAnd here we fill our list: maplist. To do that, we iterate over our parameter file with the pmap() functional and an anonymous function containing the guts of our process.\n\nmaplist&lt;-poverty_data %&gt;%\n  pmap( #use pmap so we can provide df as parameter file\n    \n    function(...){ #function takes in all variables in df because of dots param\n      \n      parms&lt;-rlang::list2(...) #extract all var values for current iteration into named list\n      \n      #save plot to p\n      p&lt;-get_acs( #api call returns county-level data with polygons\n        geography=\"county\"\n        ,variables=\"B19013_001\" #median income\n        ,state=parms$GEOID #note use of parms list\n        ,geometry=TRUE #include polygons\n        ,year=parms$year #again here\n      ) %&gt;%\n        mutate(\n          goodlabel=case_when(\n            rank(estimate,na.last=NA,ties.method=\"first\")==1|\n              percent_rank(estimate)==1\n              ~str_replace(NAME,\"(.+)(,.+)\",\"\\\\1\") %&gt;% str_remove(\" County\")\n            ,TRUE~NA_character_\n          )\n        ) %&gt;%\n        ggplot()+\n          #geom for plotting shapefile polygons\n          geom_sf(\n              size=0.05\n              ,color=\"#000000\"\n              ,aes(fill=as.numeric(estimate))\n          )+\n          geom_sf_label(\n              aes(label=goodlabel)\n              ,color=\"#000000\"\n              ,vjust=1\n          )+\n          coord_sf(crs=4326)+\n          scale_fill_viridis_c(\n            option=\"viridis\"\n            ,breaks=seq(0,200000,by=10000)\n            ,labels=dollar\n          )+\n          labs(\n            title=str_glue(\"{parms$NAME} Median Income by County\"),\n            subtitle=str_glue(\n              \"American Community Survey 5-Year Estimates {parms$year-4}-{parms$year}\\n\"\n              ,\"Highest and Lowest Income Counties Labelled\"\n            )\n          )+\n          guides(fill=guide_colorbar(\"Median\\nPast-Year\\nHH Income\"))+\n          theme_bw()+\n          theme_update(legend.key.height=unit(.35,\"in\"))\n      \n      list(\"state_abb\"=parms$state_abb,\"state\"=parms$NAME,\"plot\"=p)\n      \n    }\n    \n  )\n\nAt this point, maplist has been populated, and we can extract plot objects from it. First, let’s try just returning the first element. Recall that because our parameter file was sorted highest to lowest in terms of the proportion of the state population with household income below the poverty limit, the first element of our list will contain a plot for the most impoverished state.\n\npluck(maplist,1)$plot\n\n\n\n\n\n\n\n\nWe can also walk over the list to present ranges of its elements. Here we look at the 5 least impoverished states. Note that in this case we need an explicit print() to force the plots out of the walk functional environment.\n\nwalk(50:46,~pluck(maplist,.x)$plot %&gt;% print())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOr we can extract the map corresponding to a specific state of interest. We can do this because we loaded each element of maplist with a list containing both a plot object and state identifiers.\n\ndetect(maplist,~.x$state==\"New York\")$plot\n\n\n\n\n\n\n\ndetect(maplist,~.x$state==\"Texas\")$plot\n\n\n\n\n\n\n\ndetect(maplist,~.x$state==\"California\")$plot\n\n\n\n\n\n\n\n\nIn conclusion… maps are fun, and lists are useful!\n\n\n\nCitationBibTeX citation:@online{couzens2025,\n  author = {Couzens, Lance},\n  title = {Building and {Working} with a {List} of Ggplot {Objects} in\n    {R}},\n  date = {2025-03-22},\n  url = {https://mostlyunoriginal.github.io/posts/2025-03-22-Choropleths-and-LIst-Retrieval-Fun/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCouzens, Lance. 2025. “Building and Working with a List of Ggplot\nObjects in R.” March 22, 2025. https://mostlyunoriginal.github.io/posts/2025-03-22-Choropleths-and-LIst-Retrieval-Fun/."
  },
  {
    "objectID": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html",
    "href": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html",
    "title": "R vs. Python Query Compute Time Example",
    "section": "",
    "text": "Let’s compare the compute time needed for an equivalent operation between Python and R. The operation is to:\nIn Python, we will use polars with lazy evaluation. In R, we will use dplyr, dtplyr, and tidytable. The latter two packages interpret dplyr syntax and deploy the data.table equivalent for efficiency."
  },
  {
    "objectID": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html#plain-dplyr",
    "href": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html#plain-dplyr",
    "title": "R vs. Python Query Compute Time Example",
    "section": "Plain dplyr",
    "text": "Plain dplyr\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(hms)\n\n\nAttaching package: 'hms'\n\nThe following object is masked from 'package:lubridate':\n\n    hms\n\nstart&lt;-Sys.time()\n\nrows&lt;-data.table::fread(\"big.csv\") %&gt;%\n  group_by(id) %&gt;%\n  summarize(across(where(is.double),mean),.groups=\"keep\") %&gt;%\n  filter(if_any(where(is.double),~.x&gt;.4)) %&gt;%\n  nrow()\n\nend&lt;-Sys.time()\n\nprint(str_glue(\"{rows} rows returned\\nelapsed time for query: {as_hms(end-start)}\"))\n\n301 rows returned\nelapsed time for query: 00:01:57.947875"
  },
  {
    "objectID": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html#dtplyr",
    "href": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html#dtplyr",
    "title": "R vs. Python Query Compute Time Example",
    "section": "dtplyr",
    "text": "dtplyr\nThis is stylistically the R version that is most similar to the polars approach, but it does come with some downsides in that not all dplyr functionality is supported. In this example that is most obvious in the inability to use tidyselect helpers in summarize() and filter().\n\nlibrary(dtplyr,warn.conflicts=F)\n\nstart&lt;-Sys.time()\n\nbig&lt;-data.table::fread(\"big.csv\")\n\nvarnames&lt;-setdiff(colnames(big),\"id\")\n\nrows&lt;-lazy_dt(big) %&gt;%\n  group_by(id) %&gt;%\n  summarize(across(all_of(varnames),mean),.groups=\"keep\") %&gt;%\n  filter(if_any(all_of(varnames),~.x&gt;.4)) %&gt;%\n  collect() %&gt;%\n  nrow()\n\nend&lt;-Sys.time()\n\nprint(str_glue(\"{rows} rows returned\\nelapsed time for query: {as_hms(end-start)}\"))\n\n301 rows returned\nelapsed time for query: 00:00:43.045766"
  },
  {
    "objectID": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html#tidytable",
    "href": "posts/2025-03-19-R-v-Python-Compute-Time-Ex/index.html#tidytable",
    "title": "R vs. Python Query Compute Time Example",
    "section": "tidytable",
    "text": "tidytable\nThis should be computationally comparable to the dtplyr approach as both are deploying data.table behind the scenes, but this approach has the benefit of preserving the plain dplyr syntax, including the ability to use tidyselect helpers.\n\nstart&lt;-Sys.time()\n\nrows&lt;-data.table::fread(\"big.csv\") %&gt;%\n  tidytable::group_by(id) %&gt;%\n  tidytable::summarize(tidytable::across(where(is.double),mean),.groups=\"keep\") %&gt;%\n  tidytable::filter(tidytable::if_any(where(is.double),~.x&gt;.4)) %&gt;%\n  nrow()\n\nend&lt;-Sys.time()\n\nprint(str_glue(\"{rows} rows returned\\nelapsed time for query: {as_hms(end-start)}\"))\n\n301 rows returned\nelapsed time for query: 00:00:56.428901"
  },
  {
    "objectID": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html",
    "href": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html",
    "title": "Building a Technical Trading Data & Analytics Pipeline",
    "section": "",
    "text": "As a person with a strong background in analytics and a love of programming, I’ve always wanted to have a go at technical investing, using my own pipeline. I’ve finally taken the project on in earnest, and I’m going to chronicle the twists and turns it takes on the blog—this is Part 1.\nSo, what do I mean by ‘pipeline’ in this context? Essentially, I mean ingesting market data, algorithmically curating buy candidates, tracking existing positions for sell signals, and all the nitty gritty in-betweens that entails. I envision four high-level components:\n\nData ingestion and transformation,\nApplication of a model to identify and rank buy candidates,\nDaily, automated report creation to help me make decisions on buy candidates, and\nDaily/intraday reporting/monitoring for existing positions.\n\nI’ve started on numbers 1 and 3, so I will cover some of that here."
  },
  {
    "objectID": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#background",
    "href": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#background",
    "title": "Building a Technical Trading Data & Analytics Pipeline",
    "section": "",
    "text": "As a person with a strong background in analytics and a love of programming, I’ve always wanted to have a go at technical investing, using my own pipeline. I’ve finally taken the project on in earnest, and I’m going to chronicle the twists and turns it takes on the blog—this is Part 1.\nSo, what do I mean by ‘pipeline’ in this context? Essentially, I mean ingesting market data, algorithmically curating buy candidates, tracking existing positions for sell signals, and all the nitty gritty in-betweens that entails. I envision four high-level components:\n\nData ingestion and transformation,\nApplication of a model to identify and rank buy candidates,\nDaily, automated report creation to help me make decisions on buy candidates, and\nDaily/intraday reporting/monitoring for existing positions.\n\nI’ve started on numbers 1 and 3, so I will cover some of that here."
  },
  {
    "objectID": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#data-ingestion",
    "href": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#data-ingestion",
    "title": "Building a Technical Trading Data & Analytics Pipeline",
    "section": "Data Ingestion",
    "text": "Data Ingestion\nI’m going to focus exclusively on stocks to start, and I’ll be getting my data from Polygon.io—they have a variety of data offerings across various personal and business tiers (including a free option). I’ll be using the Stocks Starter plan, which provides a decent amount of historical data aggregated in flat files by day or minute via Amazon S3 as well as near-real-time data via API.\nMy core data object that will serve as input to the curation model will be a Python (Polars) DataFrame of daily aggregates for all U.S. stocks (~10K) over a flexible window of time through the prior trading day. I’ll build the DataFrame from flat files using the Python Boto3 SDK for S3 and two custom functions.\n\nFunction 1: List Files\nThis function returns a list of file names satisfying parameterized criteria (day vs. minute, last day, window size, etc.).\n\ndef list_hist_files(\n        kind='day_aggs',\n        last_day='2025-03-28',\n        window=30,\n        prefix='us_stocks_sip',\n        bucket_name='flatfiles',\n        bookend=False,\n    ):\n\n    session=boto3.Session(\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key,\n    )\n\n    s3=session.client(\n        's3',\n        endpoint_url='https://files.polygon.io',\n        config=Config(signature_version='s3v4'),\n    )\n\n    paginator=s3.get_paginator('list_objects_v2')\n\n    dates=[]\n    end_date=datetime.strptime(last_day,'%Y-%m-%d')\n    for delta in range(window+1):\n        temp_past_date=end_date-timedelta(days=delta)\n        dates.append(datetime.strftime(temp_past_date,'%Y-%m-%d'))\n\n    files=[]\n    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n        for obj in page['Contents']:\n            if obj['Key'].find(kind)&gt;=0 and re.sub('.*(\\\\d{4}-\\\\d{2}-\\\\d{2}).*','\\\\1',obj['Key']) in dates: \n                files.append(obj['Key'])\n\n    if bookend and len(files)&gt;2:\n        files=[files[0],files[-1]]\n\n    return files\n\n\n\nFunction 2: Ingest Files\nThe second function reads a single, dated file for the full market or for an optional subset of tickers into memory and returns a Polars DataFrame. This function has a simple positional parameterization, as it’s intended to be called via the itertools.starmap() functional.\n\ndef get_hist_data(file,tickers):\n\n    date=re.sub('.*(\\\\d{4}-\\\\d{2}-\\\\d{2}).*','\\\\1',file)\n\n    session=boto3.Session(\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key,\n    )\n\n    s3=session.client(\n        's3',\n        endpoint_url='https://files.polygon.io',\n        config=Config(signature_version='s3v4'),\n    )\n\n    response=s3.get_object(Bucket='flatfiles',Key=file)\n    compressed_data=response[\"Body\"].read()\n\n    with gzip.GzipFile(fileobj=io.BytesIO(compressed_data),mode=\"rb\") as f:\n        if tickers: df=pl.scan_csv(f).filter(pl.col('ticker').is_in(tickers)).collect()\n        else: df=pl.read_csv(f)\n\n    return df.insert_column(1,pl.lit(date).alias(\"date\"))"
  },
  {
    "objectID": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#data-transormation",
    "href": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#data-transormation",
    "title": "Building a Technical Trading Data & Analytics Pipeline",
    "section": "Data Transormation",
    "text": "Data Transormation\nNext, I pull in the data and create some metrics, including candlesticks, short and long simple moving averages, moving average convergence/divergence (MACD) indicator and signal (its moving average), and the relative strength index (RSI). Note that I convert to a Pandas DataFrame here to make the data readable in a subsequent R block—that’s just a byproduct of this post being written in Quarto. This portion of the pipeline will be scripted when implemented.\n\nimport polars as pl\nimport itertools as it\nimport boto3\nfrom botocore.config import Config\nimport tempfile\nimport gzip\nimport io\nimport re\nfrom datetime import datetime, timedelta\nfrom polygon import RESTClient\nimport polars.selectors as cs\nfrom dataclasses import asdict\n\nwith open(\"/Users/lance/Desktop/TechInvest/scripts/sandbox/01_GetHistAggs.py\") as script:\n    exec(script.read())\n\nwith open(\"/Users/lance/Desktop/TechInvest/keys.py\") as script:\n    exec(script.read())\n\niterator=it.product(\n    list_hist_files(kind=\"day_aggs\",last_day=r.params[\"ref_date\"],window=r.params[\"window\"],bookend=False),\n    [[r.params[\"ticker\"]]],\n)\n\ndf=it.starmap(get_hist_data,iterator)\n\ndf=(\n    pl.concat(list(df))\n    .lazy()\n    .sort(\"ticker\",\"window_start\")\n    .with_columns(\n        pl.col(\"close\").rolling_mean(window_size=r.params[\"sma_l\"]).over(\"ticker\").alias(\"sma_l\"),\n        pl.col(\"close\").rolling_mean(window_size=r.params[\"sma_s\"]).over(\"ticker\").alias(\"sma_s\"),\n        (pl.col(\"close\").ewm_mean(span=12,min_samples=12)-\n            pl.col(\"close\").ewm_mean(span=26,min_samples=26)\n        ).over(\"ticker\").alias(\"MACD\"),\n        (pl.col(\"close\")*2-pl.col(\"close\").rolling_sum(window_size=2)).over(\"ticker\").alias(\"rsi_diff\"),\n        pl.when(pl.col(\"close\")&gt;pl.col(\"open\")).then(1)\n        .otherwise(-1)\n        .alias(\"candle_color\"),\n        pl.max_horizontal(\"open\",\"close\").alias(\"candle_high\"),\n        pl.min_horizontal(\"open\",\"close\").alias(\"candle_low\"),\n        pl.mean_horizontal(\"open\",\"close\").alias(\"candle_mid\"),\n    )\n    .with_columns(\n        pl.col(\"MACD\").ewm_mean(span=9,min_samples=9).over(\"ticker\").alias(\"signal\"),\n        pl.when(pl.col(\"rsi_diff\")&gt;0).then(\"rsi_diff\")\n        .otherwise(0)\n        .alias(\"U\"),\n        pl.when(pl.col(\"rsi_diff\")&lt;0).then(-pl.col(\"rsi_diff\"))\n        .otherwise(0)\n        .alias(\"D\"),\n    )\n    .with_columns(\n        (pl.col(\"MACD\")-pl.col(\"signal\")).alias(\"histogram\"),\n        ((pl.col(\"U\").ewm_mean(min_samples=14,alpha=1/14))/(pl.col(\"D\").ewm_mean(min_samples=14,alpha=1/14))).alias(\"RS\"),\n    )\n    .with_columns((100-100/(1+pl.col(\"RS\"))).alias(\"RSI\"))\n    .filter(pl.col(\"signal\").is_not_null())\n    .collect()\n    .to_pandas()\n)"
  },
  {
    "objectID": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#a-graphics-template-for-buy-candidate-analysis-and-position-monitoring",
    "href": "posts/2025-04-01-Tech-Invest-Pipeline-Part1/index.html#a-graphics-template-for-buy-candidate-analysis-and-position-monitoring",
    "title": "Building a Technical Trading Data & Analytics Pipeline",
    "section": "A Graphics Template for Buy Candidate Analysis and Position Monitoring",
    "text": "A Graphics Template for Buy Candidate Analysis and Position Monitoring\nI could probably develop these graphics in Python, but I’ve just got way too much ggplot experience at this point and would rather do this part in R. The idea is to present a consistent set of metrics I can use to make buy/sell decisions. I think these will be embedded in ticker-specific html reports along with other relevant information as of yet undetermined. Here’s the code with some example output for Apple stock over a 10-week window ending on April 1, 2025.\n\nlibrary(tidyverse)\nlibrary(reticulate)\nlibrary(patchwork)\nlibrary(ggthemes)\n\nbg&lt;-\"#7AD151FF\"\nr&lt;-\"#31688EFF\"\n\nhotline&lt;-\"#FDE725FF\"\ncoldline&lt;-\"#1F988BFF\"\n\ntheme&lt;-theme_set(theme_solarized(light=FALSE))+\n    theme_update(\n        axis.text.x=element_blank(),axis.ticks.x=element_blank(),\n        axis.text.y=element_text(color=\"#bbbbbb\")\n    )\n\ng2&lt;-ggplot(py$df,aes(x=as_date(date)))+\n    geom_hline(yintercept=0,linewidth=.5,color=\"#111111\")+\n    geom_col(aes(y=histogram,fill=MACD&gt;signal),color=\"#111111\")+\n    scale_x_date(\n        limits=c(min(as_date(py$df$date))-1,max(as_date(py$df$date))+1),\n        date_breaks=\"1 week\",\n        date_minor_breaks=\"1 day\",\n        expand=expansion(add=0),\n    )+\n    scale_y_continuous()+\n    scale_fill_manual(values=c(r,bg))+\n    labs(y=NULL,x=NULL)+\n    guides(color=\"none\",fill=\"none\")\n\nu&lt;-layer_scales(g2)$x$limits[[2]] %&gt;% as_date()\nl&lt;-layer_scales(g2)$x$limits[[1]] %&gt;% as_date()\n\ng1&lt;-ggplot(py$df,aes(x=as_date(date)))+\n    geom_hline(yintercept=0,linetype=2,linewidth=.5,color=\"#bbbbbb\")+\n    geom_line(aes(y=signal),color=coldline,linewidth=1.1)+\n    geom_line(aes(y=MACD),color=hotline,linewidth=1.1)+\n    scale_x_date(\n        limits=c(l,u),\n        date_breaks=\"1 week\",\n        date_minor_breaks=\"1 day\",\n        expand=expansion(add=0),\n    )+\n    scale_y_continuous()+\n    labs(y=NULL,x=NULL)+\n    guides(color=\"none\",fill=\"none\")\n\ng3&lt;-ggplot(py$df,aes(x=as_date(date)))+\n    theme_update(\n        axis.text.x=element_text(angle=45,hjust=1,vjust=1,color=\"#bbbbbb\"),\n        axis.ticks.x=element_line(),\n    )+\n    geom_line(aes(y=RSI),linewidth=1.1,color=hotline)+\n    annotate(\n        geom=\"rect\",\n        fill=coldline,\n        xmin=l,\n        xmax=u,\n        ymin=30,\n        ymax=70,\n        alpha=0.5,\n    )+\n    scale_x_date(\n        limits=c(l,u),\n        date_breaks=\"1 week\",\n        date_minor_breaks=\"1 day\",\n        expand=expansion(add=0),\n    )+\n    scale_y_continuous(limits=c(0,100),breaks=c(0,30,70,100))+\n    labs(y=NULL,x=NULL)+\n    guides(color=\"none\",fill=\"none\")+\n    theme_update(\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n    )\n\np&lt;-ggplot(py$df,aes(x=as_date(date)))+\n    geom_line(aes(y=sma_l),color=coldline,linewidth=1.1)+\n    geom_line(aes(y=sma_s),color=hotline,linewidth=1.1)+\n    geom_linerange(aes(ymax=high,ymin=low,color=factor(candle_color)),linewidth=1.1)+\n    geom_tile(\n        aes(\n            y=candle_mid,\n            height=candle_high-candle_low,\n            fill=factor(candle_color),\n        ),\n        width=.8,\n        linewidth=.4,\n        color=\"#111111\",\n    )+\n    scale_x_date(\n        limits=c(l,u),\n        date_breaks=\"1 week\",\n        date_minor_breaks=\"1 day\",\n        expand=expansion(add=0),\n    )+\n    scale_fill_manual(values=c(r,bg))+\n    scale_color_manual(values=c(r,bg))+\n    scale_y_continuous(labels=scales::dollar)+\n    labs(y=NULL,x=NULL)+\n    ggtitle(str_glue(\"Ticker: {params$ticker}\"))+\n    guides(color=\"none\",fill=\"none\")\n\np / g1 / g2 / g3 + plot_layout(nrow=4,heights=c(3,1,1,1))\n\n\n\n\n\n\n\n\nMore to come, but that’s it for now!"
  },
  {
    "objectID": "posts/2025-03-20-2-Options-Parameterizing-R-w-Code/index.html",
    "href": "posts/2025-03-20-2-Options-Parameterizing-R-w-Code/index.html",
    "title": "Decoupling Dynamic Code from a Static R Codebase",
    "section": "",
    "text": "Oftentimes the best way to keep code working is to just not touch it. And while even the best, most stable code can’t escape tweaking forever, there are some types of changes that can at least be made without even opening an otherwise stable and static codebase, assuming it’s been set up to allow that.\nSuppose for example that we have an estimation pipeline that runs every year. In most years there are no changes to the methods or the structure of inputs/outputs, but every year there are some unavoidable changes to recode specifications. In this scenario, we have to be able to update the process but ideally in a way that minimizes both the effort required to QC the changes and the probability that something breaks. We can minimize the breakage potential by not opening the code at all, and we can minimize QC time by extracting only the affected code into a parameter file.\nHere are two ways to do that.\n\nOption 1 - A Separate Script\nIn this option, we can store the recode logic in a separate R script. Here we define two new recodes, cyl.rec and mpg.rec based on the mtcars data frame. The rules are stored in vectors with each vector position containing, as strings, individual case_when() conditions and assignments.\n\nlibrary(tidyverse)\n\n#this part can exist in a separate script\nparms&lt;-tribble(\n  ~newvar,     ~rules,\n  \"cyl.rec\",   c(\"cyl==4~1\",\"cyl==6~2\",\"cyl==8~3\"),\n  \"mpg.rec\",   c(\"mpg&lt;15~'very bad'\",\"mpg&lt;20~'bad'\",\"mpg&lt;25~'good'\",\"TRUE~'very good'\")\n)\n\nWe then have a static codebase that walks over the parameter file, creating recodes according to whatever code is found there.\nTo achieve this, we utilize purrr::pwalk() to iterate over the parameter file parms, applying for each row an anonymous function that creates the recode corresponding to that row.\nThe recode is created by injecting parms$newvar as the new variable name, and splicing (via !!!) the vector of conditions from parms$rules into the body of case_when(). Notably, for each iteration, cars is read in from the global environment, the recode is created, and cars is written to the global environment. Alternatively, we could create within the function body a data frame containing only the newly-defined column, capture them across iterations in a list (using purrr::pmap() instead of purrr::pwalk()) and column bind the list along with cars. I’ve done it both ways, but I prefer the global environment overwrite approach used below.\n\n#this part represents a static codebase that would follow a source() call \n# to the parameter file-generating script\n\ncars&lt;-mtcars %&gt;%\n  rownames_to_column(\"car\")\n\npwalk(\n  parms\n  ,function(newvar,rules,df=cars){\n\n    df.name&lt;-deparse(substitute(df))\n    \n    df %&gt;%\n      mutate(!!newvar:=case_when(!!!rlang::parse_exprs(rules))) %&gt;% \n      assign(df.name,.,envir=globalenv())\n    \n  }\n)\n\nselect(cars,car,cyl,cyl.rec,mpg,mpg.rec)\n\n                   car cyl cyl.rec  mpg   mpg.rec\n1            Mazda RX4   6       2 21.0      good\n2        Mazda RX4 Wag   6       2 21.0      good\n3           Datsun 710   4       1 22.8      good\n4       Hornet 4 Drive   6       2 21.4      good\n5    Hornet Sportabout   8       3 18.7       bad\n6              Valiant   6       2 18.1       bad\n7           Duster 360   8       3 14.3  very bad\n8            Merc 240D   4       1 24.4      good\n9             Merc 230   4       1 22.8      good\n10            Merc 280   6       2 19.2       bad\n11           Merc 280C   6       2 17.8       bad\n12          Merc 450SE   8       3 16.4       bad\n13          Merc 450SL   8       3 17.3       bad\n14         Merc 450SLC   8       3 15.2       bad\n15  Cadillac Fleetwood   8       3 10.4  very bad\n16 Lincoln Continental   8       3 10.4  very bad\n17   Chrysler Imperial   8       3 14.7  very bad\n18            Fiat 128   4       1 32.4 very good\n19         Honda Civic   4       1 30.4 very good\n20      Toyota Corolla   4       1 33.9 very good\n21       Toyota Corona   4       1 21.5      good\n22    Dodge Challenger   8       3 15.5       bad\n23         AMC Javelin   8       3 15.2       bad\n24          Camaro Z28   8       3 13.3  very bad\n25    Pontiac Firebird   8       3 19.2       bad\n26           Fiat X1-9   4       1 27.3 very good\n27       Porsche 914-2   4       1 26.0 very good\n28        Lotus Europa   4       1 30.4 very good\n29      Ford Pantera L   8       3 15.8       bad\n30        Ferrari Dino   6       2 19.7       bad\n31       Maserati Bora   8       3 15.0       bad\n32          Volvo 142E   4       1 21.4      good\n\n\n\n\nOption 2 - Code Stored as Text in a Separate File (like a csv)\nOption 2 does the same thing—creating recodes metaprogrammatically by storing the code as data—but may be a better fit if we want to store the code in text-based, tabular format rather than in an R script. This can be useful, for example, if we want someone who is a subject-matter expert but not an R programmer to write or review the recode code (in this case we could even break down the conditions in the parameter file further to strip out the case_when() syntax and reassemble as necessary in the static codebase).\n\n#this part can exist in .csv or .xlsx file\nparms.alt&lt;-tribble(\n  ~newvar,     ~rules,\n  \"cyl.rec\",   \"cyl==4~1\",\n  \"cyl.rec\",   \"cyl==6~2\",\n  \"cyl.rec\",   \"cyl==8~3\",\n  \"mpg.rec\",   \"mpg&lt;15~'very bad'\",\n  \"mpg.rec\",   \"mpg&lt;20~'bad'\",\n  \"mpg.rec\",   \"mpg&lt;25~'good'\",\n  \"mpg.rec\",   \"TRUE~'very good'\"\n) \n\nThe main difference on the static codebase side is that we group the parameter file by newvar and use group_walk() to apply our anonymous function after extracting the rules vector manually.\n\n#this part represents a static codebase that would follow an ingestion step\n# that reads in the parameter file from wherever it's stored\n\ncars&lt;-mtcars %&gt;%\n  rownames_to_column(\"car\")\n\nparms.alt %&gt;%\n  group_by(newvar) %&gt;%\n  group_walk(\n    function(rules,group,df=cars){\n      \n      df.name&lt;-deparse(substitute(df))\n      \n      newvar&lt;-pull(group,newvar)\n      rules&lt;-pull(rules,rules)\n\n      df %&gt;%\n        mutate(!!newvar:=case_when(!!!rlang::parse_exprs(rules))) %&gt;%\n        assign(df.name,.,envir=globalenv())\n      \n    }\n  )\n\nselect(cars,car,cyl,cyl.rec,mpg,mpg.rec)\n\n                   car cyl cyl.rec  mpg   mpg.rec\n1            Mazda RX4   6       2 21.0      good\n2        Mazda RX4 Wag   6       2 21.0      good\n3           Datsun 710   4       1 22.8      good\n4       Hornet 4 Drive   6       2 21.4      good\n5    Hornet Sportabout   8       3 18.7       bad\n6              Valiant   6       2 18.1       bad\n7           Duster 360   8       3 14.3  very bad\n8            Merc 240D   4       1 24.4      good\n9             Merc 230   4       1 22.8      good\n10            Merc 280   6       2 19.2       bad\n11           Merc 280C   6       2 17.8       bad\n12          Merc 450SE   8       3 16.4       bad\n13          Merc 450SL   8       3 17.3       bad\n14         Merc 450SLC   8       3 15.2       bad\n15  Cadillac Fleetwood   8       3 10.4  very bad\n16 Lincoln Continental   8       3 10.4  very bad\n17   Chrysler Imperial   8       3 14.7  very bad\n18            Fiat 128   4       1 32.4 very good\n19         Honda Civic   4       1 30.4 very good\n20      Toyota Corolla   4       1 33.9 very good\n21       Toyota Corona   4       1 21.5      good\n22    Dodge Challenger   8       3 15.5       bad\n23         AMC Javelin   8       3 15.2       bad\n24          Camaro Z28   8       3 13.3  very bad\n25    Pontiac Firebird   8       3 19.2       bad\n26           Fiat X1-9   4       1 27.3 very good\n27       Porsche 914-2   4       1 26.0 very good\n28        Lotus Europa   4       1 30.4 very good\n29      Ford Pantera L   8       3 15.8       bad\n30        Ferrari Dino   6       2 19.7       bad\n31       Maserati Bora   8       3 15.0       bad\n32          Volvo 142E   4       1 21.4      good\n\n\n\nIn either case, the recode changes are easy to QC and we eliminate the chance that we could break stable code by not even having to open it.\n\n\n\n\nCitationBibTeX citation:@online{couzens2025,\n  author = {Couzens, Lance},\n  title = {Decoupling {Dynamic} {Code} from a {Static} {R} {Codebase}},\n  date = {2025-03-20},\n  url = {https://mostlyunoriginal.github.io/posts/2025-03-20-2-Options-Parameterizing-R-w-Code/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCouzens, Lance. 2025. “Decoupling Dynamic Code from a Static R\nCodebase.” March 20, 2025. https://mostlyunoriginal.github.io/posts/2025-03-20-2-Options-Parameterizing-R-w-Code/."
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "",
    "text": "Before diving into the examples below, it’s important to acknowledge some general differences between R and Python and specific differences in style and approach between Tidy- and Polars-style data manipulation. First and foremost: Python has a strong object orientation while R is essentially a functional language. The practical impact of that difference here is that Python objects are manipulated, or their attributes extracted, by way of methods, while R objects are inputs and outputs of functions. But Python uses functions too, and in fact methods are themselves functions, so this can be very confusing!\nWhat is a method, then? In simple terms, it’s a function defined as part of the blueprint for a given type (or ‘class’) of object. A Polars DataFrame is a class of object, and there are certain functions defined in that class—these are the Polars DataFrame methods. By creating a specific DataFrame, we ‘instantiate’ the class into an object, and we can deploy a predefined set of methods to do things with or to that object.\nIn both R and Python we often want to do several operations in a row without distinct assignments for each intermediate step of a process. In R—and especially in the Tidy style of R programming—we can use piping with either the magrittr or base pipes (%&gt;% and |&gt;, respectively) to achieve this. The resulting pipeline starts with an object, passes that object into a function which returns a new object which is passed into another function, and so on and so forth until the desired object is returned by the final function in the pipeline and is captured with an assignment, returned to the console, or passed as input to another pipeline or function. Consider the following example.\n\ncyls&lt;-mtcars %&gt;% #1, 5\n  distinct(cyl) %&gt;% #2\n  arrange(cyl) %&gt;% #3\n  pull() #4\n\nHere, we start with the data frame mtcars (1), which is piped as input to the distinct() function along with the column reference cyl (2), which returns a data frame containing only the column cyl and one row for each distinct value. This is piped as input to arrange() (3) along with a column reference to cyl, which returns a sorted data frame. This is piped into pull() (4), which extracts a single column (the only one there: cyl) as a vector. This final object is then assigned to the environment variable cyls (5). Now consider the Python version which utilizes a technique called ‘method chaining’.\n\ncyls=( #5\n    mtcars #1\n    .unique(\"cyl\") #2\n    .sort(\"cyl\") #3\n    .get_column(\"cyl\") #4\n)\n\nHere, we start with mtcars, a Polars DataFrame (1). We then apply the unique() method with a reference to the column cyl (2), yielding a Polars DataFrame containing the distinct values of cyl (note that it still contains all the other variables too!). Calling the sort() method sorts the rows by the values of cyl (3). The Polars DataFrame method get_column() (4) extracts a single column and yields a Polars Series (analogous to the atomic vectors that comprise R data frame columns). The resulting Series is assigned to the variable cyls (5).\nBoth of these code blocks look quite similar, and the Python version should feel familiar to anyone who employs the Tidy-style of programming in R. Now that we’ve seen method chaining in action we can introduce a twist that unlocks some additional efficiency and that may seem strange compared to the Tidy style. The Python block above utilizes what’s called ‘eager evaluation’, which means the code inside cyls=(...) is immediately evaluated and in exactly the manner we have specified. However, Polars is actually implemented in Rust (a high performance systems programming language) and has a query optimization capability that we can exploit via something called ‘lazy evaluation’. The following ‘lazy’ alternative to the previous example gathers our instructions, performs query optimization (yielding a ‘query plan’), and ultimately executes an optimized query only when we invoke the collect() method (a method of Polars LazyFrames which result from invoking the lazy() method of a regular Polars DataFrame).\n\ncyls=(\n    mtcars\n    .lazy()\n    .unique(\"cyl\")\n    .sort(\"cyl\")\n    .collect()\n    .get_column(\"cyl\")\n)\n\nNote that Polars LazyFrames do not have a get_column() method like DataFrames do—it can therefore only be invoked after collection. The advantages of lazy evaluation in this trivial example would not be noticeable but could be significant depending on the size of the data and the complexity of the query. Lazy evaluation also allows for efficient processing of larger-than-memory data frames. See the User guide for more detail. This approach may seem familiar to anyone who has used the dtplyr R package which allows the user to proved dplyr syntax which is translated into data.table (which is written primarily in C and is much faster than dplyr) under the hood.\nWithout further ado, let’s dive into some examples."
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#background",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#background",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "",
    "text": "Before diving into the examples below, it’s important to acknowledge some general differences between R and Python and specific differences in style and approach between Tidy- and Polars-style data manipulation. First and foremost: Python has a strong object orientation while R is essentially a functional language. The practical impact of that difference here is that Python objects are manipulated, or their attributes extracted, by way of methods, while R objects are inputs and outputs of functions. But Python uses functions too, and in fact methods are themselves functions, so this can be very confusing!\nWhat is a method, then? In simple terms, it’s a function defined as part of the blueprint for a given type (or ‘class’) of object. A Polars DataFrame is a class of object, and there are certain functions defined in that class—these are the Polars DataFrame methods. By creating a specific DataFrame, we ‘instantiate’ the class into an object, and we can deploy a predefined set of methods to do things with or to that object.\nIn both R and Python we often want to do several operations in a row without distinct assignments for each intermediate step of a process. In R—and especially in the Tidy style of R programming—we can use piping with either the magrittr or base pipes (%&gt;% and |&gt;, respectively) to achieve this. The resulting pipeline starts with an object, passes that object into a function which returns a new object which is passed into another function, and so on and so forth until the desired object is returned by the final function in the pipeline and is captured with an assignment, returned to the console, or passed as input to another pipeline or function. Consider the following example.\n\ncyls&lt;-mtcars %&gt;% #1, 5\n  distinct(cyl) %&gt;% #2\n  arrange(cyl) %&gt;% #3\n  pull() #4\n\nHere, we start with the data frame mtcars (1), which is piped as input to the distinct() function along with the column reference cyl (2), which returns a data frame containing only the column cyl and one row for each distinct value. This is piped as input to arrange() (3) along with a column reference to cyl, which returns a sorted data frame. This is piped into pull() (4), which extracts a single column (the only one there: cyl) as a vector. This final object is then assigned to the environment variable cyls (5). Now consider the Python version which utilizes a technique called ‘method chaining’.\n\ncyls=( #5\n    mtcars #1\n    .unique(\"cyl\") #2\n    .sort(\"cyl\") #3\n    .get_column(\"cyl\") #4\n)\n\nHere, we start with mtcars, a Polars DataFrame (1). We then apply the unique() method with a reference to the column cyl (2), yielding a Polars DataFrame containing the distinct values of cyl (note that it still contains all the other variables too!). Calling the sort() method sorts the rows by the values of cyl (3). The Polars DataFrame method get_column() (4) extracts a single column and yields a Polars Series (analogous to the atomic vectors that comprise R data frame columns). The resulting Series is assigned to the variable cyls (5).\nBoth of these code blocks look quite similar, and the Python version should feel familiar to anyone who employs the Tidy-style of programming in R. Now that we’ve seen method chaining in action we can introduce a twist that unlocks some additional efficiency and that may seem strange compared to the Tidy style. The Python block above utilizes what’s called ‘eager evaluation’, which means the code inside cyls=(...) is immediately evaluated and in exactly the manner we have specified. However, Polars is actually implemented in Rust (a high performance systems programming language) and has a query optimization capability that we can exploit via something called ‘lazy evaluation’. The following ‘lazy’ alternative to the previous example gathers our instructions, performs query optimization (yielding a ‘query plan’), and ultimately executes an optimized query only when we invoke the collect() method (a method of Polars LazyFrames which result from invoking the lazy() method of a regular Polars DataFrame).\n\ncyls=(\n    mtcars\n    .lazy()\n    .unique(\"cyl\")\n    .sort(\"cyl\")\n    .collect()\n    .get_column(\"cyl\")\n)\n\nNote that Polars LazyFrames do not have a get_column() method like DataFrames do—it can therefore only be invoked after collection. The advantages of lazy evaluation in this trivial example would not be noticeable but could be significant depending on the size of the data and the complexity of the query. Lazy evaluation also allows for efficient processing of larger-than-memory data frames. See the User guide for more detail. This approach may seem familiar to anyone who has used the dtplyr R package which allows the user to proved dplyr syntax which is translated into data.table (which is written primarily in C and is much faster than dplyr) under the hood.\nWithout further ado, let’s dive into some examples."
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-1.-basic-summarize-without-generalization-across-variables",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-1.-basic-summarize-without-generalization-across-variables",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 1. Basic Summarize without Generalization across Variables",
    "text": "Example 1. Basic Summarize without Generalization across Variables\nHere, we take on a very simple and very common task: calculating the mean of a continuous variable (mpg) by the levels of a categorical variable (cyl).\n\nR Version\nThe Tidy approach utilizes a pipeline comprised of the mtcars data frame and the group_by() and summarize() functions. Note that these functions take a data frame (or tibble) as the first argument, but prevailing style allows this to be passed implicitly (as is done here).\n\nlibrary(dplyr)\n\ntable&lt;-mtcars %&gt;%\n    group_by(cyl) %&gt;%\n    summarize(mpg.mean=mean(mpg))\n\nprint(table)\n\n# A tibble: 3 × 2\n    cyl mpg.mean\n  &lt;dbl&gt;    &lt;dbl&gt;\n1     4     26.7\n2     6     19.7\n3     8     15.1\n\n\n\n\nPython Version\nThe Polars approach below begins by reading the R mtcars data frame into the Polars LazyFrame mtcars. The LazyFrame method group_by() is invoked followed by the agg() method. agg() contains an expression that is itself a method chain which yields the mean values for each group as the new variable mpg.mean. table is a Polars DataFrame realized as the result of evaluating an optimized query plan (via collect()).\n\nimport polars as pl\n\nmtcars=pl.LazyFrame(r.mtcars)\n\nq=(\n    mtcars\n    .group_by(\"cyl\")\n    .agg(pl.col(\"mpg\").mean().alias(\"mpg.mean\"))\n)\n\ntable=q.collect()\n\nprint(table)\n\nshape: (3, 2)\n┌─────┬───────────┐\n│ cyl ┆ mpg.mean  │\n│ --- ┆ ---       │\n│ f64 ┆ f64       │\n╞═════╪═══════════╡\n│ 8.0 ┆ 15.1      │\n│ 6.0 ┆ 19.742857 │\n│ 4.0 ┆ 26.663636 │\n└─────┴───────────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-2.-basic-mutate-with-grouping-and-without-generalization",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-2.-basic-mutate-with-grouping-and-without-generalization",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 2. Basic Mutate with Grouping and without Generalization",
    "text": "Example 2. Basic Mutate with Grouping and without Generalization\nHere we want to add a new variable to our data frame—the new variable is the ratio of each value of mpg relative to the mean value for the group (defined by the levels of the variable cyl).\n\nR Version\nIn R I can create the new variable with a call to mutate() that utilizes both group-level statistics and record-level data. This can be done in a single step with very little code.\n\ntable&lt;-mtcars %&gt;%\n    group_by(cyl) %&gt;%\n    mutate(rel.mpg=mpg/mean(mpg))\n\nprint(table)\n\n# A tibble: 32 × 12\n# Groups:   cyl [3]\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb rel.mpg\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4   1.06 \n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4   1.06 \n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1   0.855\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1   1.08 \n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2   1.24 \n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1   0.917\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4   0.947\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2   0.915\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2   0.855\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4   0.973\n# ℹ 22 more rows\n\n\n\n\nPython Version\nThe Python version uses the with_columns() LazyFrame method. Here, unlike in the R version, the grouping is baked into the recode expression itself by way of over(). Aside from looking a bit different, the Polars approach is more powerful because each expression can utilize its own grouping. Note that the Polars documentation utilizes a ‘contexts’ and ‘expressions’ framework to describe what could also be referred to as methods or method chains. In this example, with_columns() is the context in which the expression yielding the new variable rel.mpg is nested.\n\nq=(\n    mtcars\n    .with_columns(\n        (pl.col(\"mpg\")/pl.col(\"mpg\").mean().over(\"cyl\")).alias(\"rel.mpg\")\n    )\n)\n\ntable=q.collect()\n\nprint(table)\n\nshape: (32, 12)\n┌──────┬─────┬───────┬───────┬───┬─────┬──────┬──────┬──────────┐\n│ mpg  ┆ cyl ┆ disp  ┆ hp    ┆ … ┆ am  ┆ gear ┆ carb ┆ rel.mpg  │\n│ ---  ┆ --- ┆ ---   ┆ ---   ┆   ┆ --- ┆ ---  ┆ ---  ┆ ---      │\n│ f64  ┆ f64 ┆ f64   ┆ f64   ┆   ┆ f64 ┆ f64  ┆ f64  ┆ f64      │\n╞══════╪═════╪═══════╪═══════╪═══╪═════╪══════╪══════╪══════════╡\n│ 21.0 ┆ 6.0 ┆ 160.0 ┆ 110.0 ┆ … ┆ 1.0 ┆ 4.0  ┆ 4.0  ┆ 1.063676 │\n│ 21.0 ┆ 6.0 ┆ 160.0 ┆ 110.0 ┆ … ┆ 1.0 ┆ 4.0  ┆ 4.0  ┆ 1.063676 │\n│ 22.8 ┆ 4.0 ┆ 108.0 ┆ 93.0  ┆ … ┆ 1.0 ┆ 4.0  ┆ 1.0  ┆ 0.855097 │\n│ 21.4 ┆ 6.0 ┆ 258.0 ┆ 110.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 1.0  ┆ 1.083936 │\n│ 18.7 ┆ 8.0 ┆ 360.0 ┆ 175.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 2.0  ┆ 1.238411 │\n│ …    ┆ …   ┆ …     ┆ …     ┆ … ┆ …   ┆ …    ┆ …    ┆ …        │\n│ 30.4 ┆ 4.0 ┆ 95.1  ┆ 113.0 ┆ … ┆ 1.0 ┆ 5.0  ┆ 2.0  ┆ 1.14013  │\n│ 15.8 ┆ 8.0 ┆ 351.0 ┆ 264.0 ┆ … ┆ 1.0 ┆ 5.0  ┆ 4.0  ┆ 1.046358 │\n│ 19.7 ┆ 6.0 ┆ 145.0 ┆ 175.0 ┆ … ┆ 1.0 ┆ 5.0  ┆ 6.0  ┆ 0.997829 │\n│ 15.0 ┆ 8.0 ┆ 301.0 ┆ 335.0 ┆ … ┆ 1.0 ┆ 5.0  ┆ 8.0  ┆ 0.993377 │\n│ 21.4 ┆ 4.0 ┆ 121.0 ┆ 109.0 ┆ … ┆ 1.0 ┆ 4.0  ┆ 2.0  ┆ 0.802591 │\n└──────┴─────┴───────┴───────┴───┴─────┴──────┴──────┴──────────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-3.-summarize-generalized-by-variable-type-with-across",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-3.-summarize-generalized-by-variable-type-with-across",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 3. Summarize Generalized by Variable Type with Across",
    "text": "Example 3. Summarize Generalized by Variable Type with Across\nIn this example we want to generate means by group (like in example 1), but across a set of columns described by a selection criteria (i.e., not by name).\n\nR Version\nAs before, we specify the grouping via group_by() and generate the means within summarize(). In order to create means for several variables not explicitly specified we can utilize across(). To get means for all variables stored as doubles, we use the helper function where() in the .cols specification. Glue syntax in the .names specification allows us to rename all affected columns.\n\nmtcars %&gt;%\n    group_by(cyl,gear) %&gt;%\n    summarize(\n        across(\n            .cols=where(is.double)\n            ,.fns=mean\n            ,.names=\"{.col}_mean\"\n        )\n    )\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 8 × 11\n# Groups:   cyl [3]\n    cyl  gear mpg_mean disp_mean hp_mean drat_mean wt_mean qsec_mean vs_mean\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     4     3     21.5      120.     97       3.7     2.46      20.0     1  \n2     4     4     26.9      103.     76       4.11    2.38      19.6     1  \n3     4     5     28.2      108.    102       4.1     1.83      16.8     0.5\n4     6     3     19.8      242.    108.      2.92    3.34      19.8     1  \n5     6     4     19.8      164.    116.      3.91    3.09      17.7     0.5\n6     6     5     19.7      145     175       3.62    2.77      15.5     0  \n7     8     3     15.0      358.    194.      3.12    4.10      17.1     0  \n8     8     5     15.4      326     300.      3.88    3.37      14.6     0  \n# ℹ 2 more variables: am_mean &lt;dbl&gt;, carb_mean &lt;dbl&gt;\n\n\n\n\nPython Version\nThe Python version looks very similar to the R version and has the same basic structure as in example 1. Here, though, instead of specifying a column with pl.col() we indicate that we want all columns stored as floats by using cs.float(). Note that there are many selector functions available, as explained here. The name method name.suffix() is used to rename all affected variables. See other name methods here.\n\nimport polars.selectors as cs\n\nq=(\n    mtcars\n    .group_by(\"cyl\",\"gear\")\n    .agg(cs.float().mean().name.suffix(\"_mean\"))\n)\n\ntable=q.collect()\n\nprint(table)\n\nshape: (8, 11)\n┌─────┬──────┬──────────┬────────────┬───┬───────────┬─────────┬─────────┬───────────┐\n│ cyl ┆ gear ┆ mpg_mean ┆ disp_mean  ┆ … ┆ qsec_mean ┆ vs_mean ┆ am_mean ┆ carb_mean │\n│ --- ┆ ---  ┆ ---      ┆ ---        ┆   ┆ ---       ┆ ---     ┆ ---     ┆ ---       │\n│ f64 ┆ f64  ┆ f64      ┆ f64        ┆   ┆ f64       ┆ f64     ┆ f64     ┆ f64       │\n╞═════╪══════╪══════════╪════════════╪═══╪═══════════╪═════════╪═════════╪═══════════╡\n│ 8.0 ┆ 3.0  ┆ 15.05    ┆ 357.616667 ┆ … ┆ 17.1425   ┆ 0.0     ┆ 0.0     ┆ 3.083333  │\n│ 4.0 ┆ 3.0  ┆ 21.5     ┆ 120.1      ┆ … ┆ 20.01     ┆ 1.0     ┆ 0.0     ┆ 1.0       │\n│ 4.0 ┆ 4.0  ┆ 26.925   ┆ 102.625    ┆ … ┆ 19.6125   ┆ 1.0     ┆ 0.75    ┆ 1.5       │\n│ 6.0 ┆ 3.0  ┆ 19.75    ┆ 241.5      ┆ … ┆ 19.83     ┆ 1.0     ┆ 0.0     ┆ 1.0       │\n│ 4.0 ┆ 5.0  ┆ 28.2     ┆ 107.7      ┆ … ┆ 16.8      ┆ 0.5     ┆ 1.0     ┆ 2.0       │\n│ 8.0 ┆ 5.0  ┆ 15.4     ┆ 326.0      ┆ … ┆ 14.55     ┆ 0.0     ┆ 1.0     ┆ 6.0       │\n│ 6.0 ┆ 4.0  ┆ 19.75    ┆ 163.8      ┆ … ┆ 17.67     ┆ 0.5     ┆ 0.5     ┆ 4.0       │\n│ 6.0 ┆ 5.0  ┆ 19.7     ┆ 145.0      ┆ … ┆ 15.5      ┆ 0.0     ┆ 1.0     ┆ 6.0       │\n└─────┴──────┴──────────┴────────────┴───┴───────────┴─────────┴─────────┴───────────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-4.-conditional-recode",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-4.-conditional-recode",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 4. Conditional Recode",
    "text": "Example 4. Conditional Recode\nIn this example we use if/else if/else logic to create a string recode of the numeric variable mpg.\n\nR Version\nIn the Tidy R approach we deploy case_when() inside of mutate() to create a recode with cascading conditional logic.\n\nmtcars %&gt;%\n    mutate(\n        mpg.cat=case_when(\n            mpg&lt;10~\"very bad\"\n            ,mpg&lt;15~\"bad\"\n            ,mpg&lt;20~\"okay\"\n            ,mpg&lt;25~\"good\"\n            ,TRUE~\"great\"\n        )\n    ) %&gt;%\n    arrange(desc(mpg))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb mpg.cat\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1   great\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1   great\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2   great\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2   great\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1   great\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2   great\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2    good\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1    good\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2    good\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1    good\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1    good\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2    good\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4    good\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4    good\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6    okay\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4    okay\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2    okay\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2    okay\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1    okay\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4    okay\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3    okay\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3    okay\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4    okay\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2    okay\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3    okay\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2    okay\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8    okay\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4     bad\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4     bad\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4     bad\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4     bad\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4     bad\n\n\n\n\nPython Version\nThe Python version is quite a bit more wordy. Note that pl.lit() is needed here to resolve ambiguity in the way column references can appear as strings in then()—in other words, we’re indicating we want the recoded values to be the provided strings, not the values of columns represented by those strings.\n\nq=(\n    mtcars\n    .with_columns(\n        pl.when(pl.col(\"mpg\")&lt;10).then(pl.lit(\"very bad\"))\n        .when(pl.col(\"mpg\")&lt;15).then(pl.lit(\"bad\"))\n        .when(pl.col(\"mpg\")&lt;20).then(pl.lit(\"okay\"))\n        .when(pl.col(\"mpg\")&lt;25).then(pl.lit(\"good\"))\n        .otherwise(pl.lit(\"great\"))\n        .alias(\"mpg.cat\")\n    )\n    .sort(\"mpg\",descending=True)\n)\n\ndf=q.collect()\n\nprint(df)\n\nshape: (32, 12)\n┌──────┬─────┬───────┬───────┬───┬─────┬──────┬──────┬─────────┐\n│ mpg  ┆ cyl ┆ disp  ┆ hp    ┆ … ┆ am  ┆ gear ┆ carb ┆ mpg.cat │\n│ ---  ┆ --- ┆ ---   ┆ ---   ┆   ┆ --- ┆ ---  ┆ ---  ┆ ---     │\n│ f64  ┆ f64 ┆ f64   ┆ f64   ┆   ┆ f64 ┆ f64  ┆ f64  ┆ str     │\n╞══════╪═════╪═══════╪═══════╪═══╪═════╪══════╪══════╪═════════╡\n│ 33.9 ┆ 4.0 ┆ 71.1  ┆ 65.0  ┆ … ┆ 1.0 ┆ 4.0  ┆ 1.0  ┆ great   │\n│ 32.4 ┆ 4.0 ┆ 78.7  ┆ 66.0  ┆ … ┆ 1.0 ┆ 4.0  ┆ 1.0  ┆ great   │\n│ 30.4 ┆ 4.0 ┆ 75.7  ┆ 52.0  ┆ … ┆ 1.0 ┆ 4.0  ┆ 2.0  ┆ great   │\n│ 30.4 ┆ 4.0 ┆ 95.1  ┆ 113.0 ┆ … ┆ 1.0 ┆ 5.0  ┆ 2.0  ┆ great   │\n│ 27.3 ┆ 4.0 ┆ 79.0  ┆ 66.0  ┆ … ┆ 1.0 ┆ 4.0  ┆ 1.0  ┆ great   │\n│ …    ┆ …   ┆ …     ┆ …     ┆ … ┆ …   ┆ …    ┆ …    ┆ …       │\n│ 14.7 ┆ 8.0 ┆ 440.0 ┆ 230.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 4.0  ┆ bad     │\n│ 14.3 ┆ 8.0 ┆ 360.0 ┆ 245.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 4.0  ┆ bad     │\n│ 13.3 ┆ 8.0 ┆ 350.0 ┆ 245.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 4.0  ┆ bad     │\n│ 10.4 ┆ 8.0 ┆ 472.0 ┆ 205.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 4.0  ┆ bad     │\n│ 10.4 ┆ 8.0 ┆ 460.0 ┆ 215.0 ┆ … ┆ 0.0 ┆ 3.0  ┆ 4.0  ┆ bad     │\n└──────┴─────┴───────┴───────┴───┴─────┴──────┴──────┴─────────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-5.-pivots",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-5.-pivots",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 5. Pivots",
    "text": "Example 5. Pivots\nIn this example we start with mtcars (a version with rownames mapped to the column car), pivot to a long file and then back to wide.\n\nR Version\nHere we use very simple forms of pivot_longer() and pivot_wider().\n\nlibrary(tidyr)\nlibrary(tibble)\n\ncars&lt;-rownames_to_column(mtcars,\"car\") %&gt;%\n  pivot_longer(\n    cols=where(is.numeric)\n    ,names_to=\"variable\"\n    ,values_to=\"value\"\n  )\n\nprint(cars)\n\n# A tibble: 352 × 3\n   car       variable  value\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 Mazda RX4 mpg       21   \n 2 Mazda RX4 cyl        6   \n 3 Mazda RX4 disp     160   \n 4 Mazda RX4 hp       110   \n 5 Mazda RX4 drat       3.9 \n 6 Mazda RX4 wt         2.62\n 7 Mazda RX4 qsec      16.5 \n 8 Mazda RX4 vs         0   \n 9 Mazda RX4 am         1   \n10 Mazda RX4 gear       4   \n# ℹ 342 more rows\n\nmtcars_w_names&lt;-cars %&gt;%\n  pivot_wider(\n    id_cols=car\n    ,names_from=\"variable\"\n    ,values_from=\"value\"\n  )\n\nprint(mtcars_w_names)\n\n# A tibble: 32 × 12\n   car           mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Mazda RX4    21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6 Valiant      18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7 Duster 360   14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8 Merc 240D    24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\n\n\nPython Version\nWith polars, going from wide to long is an unpivot and long to wide is a pivot. Note that the pivot() is only available in eager mode, as shown below.\n\nimport polars.selectors as cs\n\nq=(\n    pl.scan_csv(\"mtcars_w_names.csv\")\n    .unpivot(\n        on=cs.numeric()\n        ,index=\"car\"\n        ,variable_name=\"variable\"\n        ,value_name=\"value\"\n    )\n)\n\ncars=q.collect()\n\nprint(cars)\n\nshape: (352, 3)\n┌───────────────────┬──────────┬───────┐\n│ car               ┆ variable ┆ value │\n│ ---               ┆ ---      ┆ ---   │\n│ str               ┆ str      ┆ f64   │\n╞═══════════════════╪══════════╪═══════╡\n│ Mazda RX4         ┆ mpg      ┆ 21.0  │\n│ Mazda RX4 Wag     ┆ mpg      ┆ 21.0  │\n│ Datsun 710        ┆ mpg      ┆ 22.8  │\n│ Hornet 4 Drive    ┆ mpg      ┆ 21.4  │\n│ Hornet Sportabout ┆ mpg      ┆ 18.7  │\n│ …                 ┆ …        ┆ …     │\n│ Lotus Europa      ┆ carb     ┆ 2.0   │\n│ Ford Pantera L    ┆ carb     ┆ 4.0   │\n│ Ferrari Dino      ┆ carb     ┆ 6.0   │\n│ Maserati Bora     ┆ carb     ┆ 8.0   │\n│ Volvo 142E        ┆ carb     ┆ 2.0   │\n└───────────────────┴──────────┴───────┘\n\nmtcars_w_names=(\n    cars\n    .pivot(\n        index=\"car\"\n        ,on=\"variable\"\n        ,values=\"value\"\n        ,aggregate_function=None\n    )\n)\n\nprint(mtcars_w_names)\n\nshape: (32, 12)\n┌───────────────────┬──────┬─────┬───────┬───┬─────┬─────┬──────┬──────┐\n│ car               ┆ mpg  ┆ cyl ┆ disp  ┆ … ┆ vs  ┆ am  ┆ gear ┆ carb │\n│ ---               ┆ ---  ┆ --- ┆ ---   ┆   ┆ --- ┆ --- ┆ ---  ┆ ---  │\n│ str               ┆ f64  ┆ f64 ┆ f64   ┆   ┆ f64 ┆ f64 ┆ f64  ┆ f64  │\n╞═══════════════════╪══════╪═════╪═══════╪═══╪═════╪═════╪══════╪══════╡\n│ Mazda RX4         ┆ 21.0 ┆ 6.0 ┆ 160.0 ┆ … ┆ 0.0 ┆ 1.0 ┆ 4.0  ┆ 4.0  │\n│ Mazda RX4 Wag     ┆ 21.0 ┆ 6.0 ┆ 160.0 ┆ … ┆ 0.0 ┆ 1.0 ┆ 4.0  ┆ 4.0  │\n│ Datsun 710        ┆ 22.8 ┆ 4.0 ┆ 108.0 ┆ … ┆ 1.0 ┆ 1.0 ┆ 4.0  ┆ 1.0  │\n│ Hornet 4 Drive    ┆ 21.4 ┆ 6.0 ┆ 258.0 ┆ … ┆ 1.0 ┆ 0.0 ┆ 3.0  ┆ 1.0  │\n│ Hornet Sportabout ┆ 18.7 ┆ 8.0 ┆ 360.0 ┆ … ┆ 0.0 ┆ 0.0 ┆ 3.0  ┆ 2.0  │\n│ …                 ┆ …    ┆ …   ┆ …     ┆ … ┆ …   ┆ …   ┆ …    ┆ …    │\n│ Lotus Europa      ┆ 30.4 ┆ 4.0 ┆ 95.1  ┆ … ┆ 1.0 ┆ 1.0 ┆ 5.0  ┆ 2.0  │\n│ Ford Pantera L    ┆ 15.8 ┆ 8.0 ┆ 351.0 ┆ … ┆ 0.0 ┆ 1.0 ┆ 5.0  ┆ 4.0  │\n│ Ferrari Dino      ┆ 19.7 ┆ 6.0 ┆ 145.0 ┆ … ┆ 0.0 ┆ 1.0 ┆ 5.0  ┆ 6.0  │\n│ Maserati Bora     ┆ 15.0 ┆ 8.0 ┆ 301.0 ┆ … ┆ 0.0 ┆ 1.0 ┆ 5.0  ┆ 8.0  │\n│ Volvo 142E        ┆ 21.4 ┆ 4.0 ┆ 121.0 ┆ … ┆ 1.0 ┆ 1.0 ┆ 4.0  ┆ 2.0  │\n└───────────────────┴──────┴─────┴───────┴───┴─────┴─────┴──────┴──────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-6.-joins",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-6.-joins",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 6. Joins",
    "text": "Example 6. Joins\nIn this example we will show the various join types with two distinct but overlapping subsets of mtcars: cars with 6-cylinder engines and those with horsepower less than 110.\n\nR Version\nThis code is pretty self-explanatory.\n\ncarsl&lt;-mtcars %&gt;%\n    rownames_to_column(\"car\") %&gt;%\n    filter(cyl==6) %&gt;%\n    select(car,cyl)\n\ncarsr&lt;-mtcars %&gt;%\n    rownames_to_column(\"car\") %&gt;%\n    filter(hp&lt;110) %&gt;%\n    select(car,hp)\n\nprint(carsl)\n\n             car cyl\n1      Mazda RX4   6\n2  Mazda RX4 Wag   6\n3 Hornet 4 Drive   6\n4        Valiant   6\n5       Merc 280   6\n6      Merc 280C   6\n7   Ferrari Dino   6\n\nprint(carsr)\n\n              car  hp\n1      Datsun 710  93\n2         Valiant 105\n3       Merc 240D  62\n4        Merc 230  95\n5        Fiat 128  66\n6     Honda Civic  52\n7  Toyota Corolla  65\n8   Toyota Corona  97\n9       Fiat X1-9  66\n10  Porsche 914-2  91\n11     Volvo 142E 109\n\nleft_join(carsl,carsr,by=\"car\")\n\n             car cyl  hp\n1      Mazda RX4   6  NA\n2  Mazda RX4 Wag   6  NA\n3 Hornet 4 Drive   6  NA\n4        Valiant   6 105\n5       Merc 280   6  NA\n6      Merc 280C   6  NA\n7   Ferrari Dino   6  NA\n\nright_join(carsl,carsr,by=\"car\")\n\n              car cyl  hp\n1         Valiant   6 105\n2      Datsun 710  NA  93\n3       Merc 240D  NA  62\n4        Merc 230  NA  95\n5        Fiat 128  NA  66\n6     Honda Civic  NA  52\n7  Toyota Corolla  NA  65\n8   Toyota Corona  NA  97\n9       Fiat X1-9  NA  66\n10  Porsche 914-2  NA  91\n11     Volvo 142E  NA 109\n\ninner_join(carsl,carsr,by=\"car\")\n\n      car cyl  hp\n1 Valiant   6 105\n\nfull_join(carsl,carsr,by=\"car\")\n\n              car cyl  hp\n1       Mazda RX4   6  NA\n2   Mazda RX4 Wag   6  NA\n3  Hornet 4 Drive   6  NA\n4         Valiant   6 105\n5        Merc 280   6  NA\n6       Merc 280C   6  NA\n7    Ferrari Dino   6  NA\n8      Datsun 710  NA  93\n9       Merc 240D  NA  62\n10       Merc 230  NA  95\n11       Fiat 128  NA  66\n12    Honda Civic  NA  52\n13 Toyota Corolla  NA  65\n14  Toyota Corona  NA  97\n15      Fiat X1-9  NA  66\n16  Porsche 914-2  NA  91\n17     Volvo 142E  NA 109\n\nanti_join(carsl,carsr,by=\"car\")\n\n             car cyl\n1      Mazda RX4   6\n2  Mazda RX4 Wag   6\n3 Hornet 4 Drive   6\n4       Merc 280   6\n5      Merc 280C   6\n6   Ferrari Dino   6\n\n\n\n\nPython Version\n\ncarsl=(\n    pl.scan_csv(\"mtcars_w_names.csv\")\n    .filter(pl.col(\"cyl\")==6)\n    .select(\"car\",\"cyl\")\n)\n\ncarsr=(\n    pl.scan_csv(\"mtcars_w_names.csv\")\n    .filter(pl.col(\"hp\")&lt;110)\n    .select(\"car\",\"hp\")\n)\n\nprint(carsl.collect())\n\nshape: (7, 2)\n┌────────────────┬─────┐\n│ car            ┆ cyl │\n│ ---            ┆ --- │\n│ str            ┆ i64 │\n╞════════════════╪═════╡\n│ Mazda RX4      ┆ 6   │\n│ Mazda RX4 Wag  ┆ 6   │\n│ Hornet 4 Drive ┆ 6   │\n│ Valiant        ┆ 6   │\n│ Merc 280       ┆ 6   │\n│ Merc 280C      ┆ 6   │\n│ Ferrari Dino   ┆ 6   │\n└────────────────┴─────┘\n\nprint(carsr.collect())\n\nshape: (11, 2)\n┌────────────────┬─────┐\n│ car            ┆ hp  │\n│ ---            ┆ --- │\n│ str            ┆ i64 │\n╞════════════════╪═════╡\n│ Datsun 710     ┆ 93  │\n│ Valiant        ┆ 105 │\n│ Merc 240D      ┆ 62  │\n│ Merc 230       ┆ 95  │\n│ Fiat 128       ┆ 66  │\n│ …              ┆ …   │\n│ Toyota Corolla ┆ 65  │\n│ Toyota Corona  ┆ 97  │\n│ Fiat X1-9      ┆ 66  │\n│ Porsche 914-2  ┆ 91  │\n│ Volvo 142E     ┆ 109 │\n└────────────────┴─────┘\n\nprint(carsl.join(carsr,on=\"car\",how=\"left\").collect())\n\nshape: (7, 3)\n┌────────────────┬─────┬──────┐\n│ car            ┆ cyl ┆ hp   │\n│ ---            ┆ --- ┆ ---  │\n│ str            ┆ i64 ┆ i64  │\n╞════════════════╪═════╪══════╡\n│ Mazda RX4      ┆ 6   ┆ null │\n│ Mazda RX4 Wag  ┆ 6   ┆ null │\n│ Hornet 4 Drive ┆ 6   ┆ null │\n│ Valiant        ┆ 6   ┆ 105  │\n│ Merc 280       ┆ 6   ┆ null │\n│ Merc 280C      ┆ 6   ┆ null │\n│ Ferrari Dino   ┆ 6   ┆ null │\n└────────────────┴─────┴──────┘\n\nprint(carsl.join(carsr,on=\"car\",how=\"right\").collect())\n\nshape: (11, 3)\n┌──────┬────────────────┬─────┐\n│ cyl  ┆ car            ┆ hp  │\n│ ---  ┆ ---            ┆ --- │\n│ i64  ┆ str            ┆ i64 │\n╞══════╪════════════════╪═════╡\n│ null ┆ Datsun 710     ┆ 93  │\n│ 6    ┆ Valiant        ┆ 105 │\n│ null ┆ Merc 240D      ┆ 62  │\n│ null ┆ Merc 230       ┆ 95  │\n│ null ┆ Fiat 128       ┆ 66  │\n│ …    ┆ …              ┆ …   │\n│ null ┆ Toyota Corolla ┆ 65  │\n│ null ┆ Toyota Corona  ┆ 97  │\n│ null ┆ Fiat X1-9      ┆ 66  │\n│ null ┆ Porsche 914-2  ┆ 91  │\n│ null ┆ Volvo 142E     ┆ 109 │\n└──────┴────────────────┴─────┘\n\nprint(carsl.join(carsr,on=\"car\",how=\"inner\").collect())\n\nshape: (1, 3)\n┌─────────┬─────┬─────┐\n│ car     ┆ cyl ┆ hp  │\n│ ---     ┆ --- ┆ --- │\n│ str     ┆ i64 ┆ i64 │\n╞═════════╪═════╪═════╡\n│ Valiant ┆ 6   ┆ 105 │\n└─────────┴─────┴─────┘\n\nprint(carsl.join(carsr,on=\"car\",how=\"full\",coalesce=True).collect())\n\nshape: (17, 3)\n┌────────────────┬──────┬──────┐\n│ car            ┆ cyl  ┆ hp   │\n│ ---            ┆ ---  ┆ ---  │\n│ str            ┆ i64  ┆ i64  │\n╞════════════════╪══════╪══════╡\n│ Datsun 710     ┆ null ┆ 93   │\n│ Valiant        ┆ 6    ┆ 105  │\n│ Merc 240D      ┆ null ┆ 62   │\n│ Merc 230       ┆ null ┆ 95   │\n│ Fiat 128       ┆ null ┆ 66   │\n│ …              ┆ …    ┆ …    │\n│ Merc 280       ┆ 6    ┆ null │\n│ Mazda RX4      ┆ 6    ┆ null │\n│ Ferrari Dino   ┆ 6    ┆ null │\n│ Hornet 4 Drive ┆ 6    ┆ null │\n│ Merc 280C      ┆ 6    ┆ null │\n└────────────────┴──────┴──────┘\n\nprint(carsl.join(carsr,on=\"car\",how=\"anti\").collect())\n\nshape: (6, 2)\n┌────────────────┬─────┐\n│ car            ┆ cyl │\n│ ---            ┆ --- │\n│ str            ┆ i64 │\n╞════════════════╪═════╡\n│ Mazda RX4      ┆ 6   │\n│ Mazda RX4 Wag  ┆ 6   │\n│ Hornet 4 Drive ┆ 6   │\n│ Merc 280       ┆ 6   │\n│ Merc 280C      ┆ 6   │\n│ Ferrari Dino   ┆ 6   │\n└────────────────┴─────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-7.-function-for-n-pct-by-grouping-variables",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-7.-function-for-n-pct-by-grouping-variables",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 7. Function for n & pct by Grouping Variables",
    "text": "Example 7. Function for n & pct by Grouping Variables\nHere we want a custom function to create simple, list-style frequency tables based on one or more variables provided by the user.\n\nR Version\nWe use dynamic dots (...) here to tunnel in the variables provided by the user in the function call. This is powerful and flexible, allowing for 0+ variables provided as naked symbols rather than strings (doit()); an alternative version (doit2()) also uses dynamic dots, but with the intention to call with variable names provided as strings—this scales up better and is more comparable to the python version.\n\nlibrary(rlang)\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n    flatten_raw, invoke, splice\n\nlibrary(purrr)\n\ndoit&lt;-function(df,...){\n  df %&gt;%\n    ungroup() %&gt;%\n    mutate(N=n()) %&gt;%\n    group_by(...) %&gt;%\n    summarize(n=n(),pct=n()*100/mean(N),.groups=\"drop\") %&gt;%\n    mutate(cumn=cumsum(n),cumpct=cumsum(pct))\n}\n\ndoit(mtcars)\n\n# A tibble: 1 × 4\n      n   pct  cumn cumpct\n  &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1    32   100    32    100\n\ndoit(mtcars,cyl)\n\n# A tibble: 3 × 5\n    cyl     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4    11  34.4    11   34.4\n2     6     7  21.9    18   56.2\n3     8    14  43.8    32  100  \n\ndoit(mtcars,cyl,gear)\n\n# A tibble: 8 × 6\n    cyl  gear     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4     3     1  3.12     1   3.12\n2     4     4     8 25        9  28.1 \n3     4     5     2  6.25    11  34.4 \n4     6     3     2  6.25    13  40.6 \n5     6     4     4 12.5     17  53.1 \n6     6     5     1  3.12    18  56.2 \n7     8     3    12 37.5     30  93.8 \n8     8     5     2  6.25    32 100   \n\ndoit2&lt;-function(df,...){\n    vars&lt;-dots_list(...) %&gt;%\n        list_c() %&gt;%\n        syms()\n\n    df %&gt;%\n        ungroup() %&gt;%\n        mutate(N=n()) %&gt;%\n        group_by(!!!vars) %&gt;%\n        summarize(n=n(),pct=n()*100/mean(N),.groups=\"drop\") %&gt;%\n        mutate(cumn=cumsum(n),cumpct=cumsum(pct))\n}\n\ndoit2(mtcars)\n\n# A tibble: 1 × 4\n      n   pct  cumn cumpct\n  &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1    32   100    32    100\n\ndoit2(mtcars,\"cyl\")\n\n# A tibble: 3 × 5\n    cyl     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4    11  34.4    11   34.4\n2     6     7  21.9    18   56.2\n3     8    14  43.8    32  100  \n\ndoit2(mtcars,\"cyl\",\"gear\")\n\n# A tibble: 8 × 6\n    cyl  gear     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4     3     1  3.12     1   3.12\n2     4     4     8 25        9  28.1 \n3     4     5     2  6.25    11  34.4 \n4     6     3     2  6.25    13  40.6 \n5     6     4     4 12.5     17  53.1 \n6     6     5     1  3.12    18  56.2 \n7     8     3    12 37.5     30  93.8 \n8     8     5     2  6.25    32 100   \n\n\n\n\nPython Version\nThe version below gets very close! The only differences are that the python version of doit() doesn’t work as-is if 0 variables are provided, and the variable names are passed as strings (i.e., this isn’t optional as with the tidy versions). This latter point should actually simplify some situations that are complex due to data mask ambiguities in tidy functions.\n\ndef doit(df,*argv):\n    q=(\n        df\n        .with_columns(pl.len().alias(\"N\"))\n        .group_by(*argv)\n        .agg(\n            pl.len().alias(\"n\")\n            ,((pl.len()*100)/pl.col(\"N\").mean()).alias(\"pct\")\n        )\n        .sort(*argv)\n        .with_columns(\n            pl.col(\"n\").cum_sum().alias(\"cumn\")\n            ,pl.col(\"pct\").cum_sum().alias(\"cumpct\")\n        )\n    )\n    table=q.collect()\n    print(table)\n\ndoit(mtcars,\"cyl\")\n\nshape: (3, 5)\n┌─────┬─────┬────────┬──────┬────────┐\n│ cyl ┆ n   ┆ pct    ┆ cumn ┆ cumpct │\n│ --- ┆ --- ┆ ---    ┆ ---  ┆ ---    │\n│ f64 ┆ u32 ┆ f64    ┆ u32  ┆ f64    │\n╞═════╪═════╪════════╪══════╪════════╡\n│ 4.0 ┆ 11  ┆ 34.375 ┆ 11   ┆ 34.375 │\n│ 6.0 ┆ 7   ┆ 21.875 ┆ 18   ┆ 56.25  │\n│ 8.0 ┆ 14  ┆ 43.75  ┆ 32   ┆ 100.0  │\n└─────┴─────┴────────┴──────┴────────┘\n\ndoit(mtcars,\"cyl\",\"gear\")\n\nshape: (8, 6)\n┌─────┬──────┬─────┬───────┬──────┬────────┐\n│ cyl ┆ gear ┆ n   ┆ pct   ┆ cumn ┆ cumpct │\n│ --- ┆ ---  ┆ --- ┆ ---   ┆ ---  ┆ ---    │\n│ f64 ┆ f64  ┆ u32 ┆ f64   ┆ u32  ┆ f64    │\n╞═════╪══════╪═════╪═══════╪══════╪════════╡\n│ 4.0 ┆ 3.0  ┆ 1   ┆ 3.125 ┆ 1    ┆ 3.125  │\n│ 4.0 ┆ 4.0  ┆ 8   ┆ 25.0  ┆ 9    ┆ 28.125 │\n│ 4.0 ┆ 5.0  ┆ 2   ┆ 6.25  ┆ 11   ┆ 34.375 │\n│ 6.0 ┆ 3.0  ┆ 2   ┆ 6.25  ┆ 13   ┆ 40.625 │\n│ 6.0 ┆ 4.0  ┆ 4   ┆ 12.5  ┆ 17   ┆ 53.125 │\n│ 6.0 ┆ 5.0  ┆ 1   ┆ 3.125 ┆ 18   ┆ 56.25  │\n│ 8.0 ┆ 3.0  ┆ 12  ┆ 37.5  ┆ 30   ┆ 93.75  │\n│ 8.0 ┆ 5.0  ┆ 2   ┆ 6.25  ┆ 32   ┆ 100.0  │\n└─────┴──────┴─────┴───────┴──────┴────────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-8.-iterate-a-custom-function",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-8.-iterate-a-custom-function",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 8. Iterate a Custom Function",
    "text": "Example 8. Iterate a Custom Function\nHere we want to apply the doit functions over parameters.\n\nR Version\nWe can use purrr::pmap() in the R version with a list of parameters. Since we defined the R version of doit to take naked symbols, the mapped version is kind of clunky—a cleaner alternative based on doit2 highlights this point.\n\nparms&lt;-list(\n    list(mtcars,mtcars)\n    ,\"var1\"=list(mtcars$cyl,mtcars$cyl)\n    ,\"var2\"=list(mtcars$gear,mtcars$am)\n)\n\npmap(parms,doit)\n\n[[1]]\n# A tibble: 8 × 6\n   var1  var2     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4     3     1  3.12     1   3.12\n2     4     4     8 25        9  28.1 \n3     4     5     2  6.25    11  34.4 \n4     6     3     2  6.25    13  40.6 \n5     6     4     4 12.5     17  53.1 \n6     6     5     1  3.12    18  56.2 \n7     8     3    12 37.5     30  93.8 \n8     8     5     2  6.25    32 100   \n\n[[2]]\n# A tibble: 6 × 6\n   var1  var2     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4     0     3  9.38     3   9.38\n2     4     1     8 25       11  34.4 \n3     6     0     4 12.5     15  46.9 \n4     6     1     3  9.38    18  56.2 \n5     8     0    12 37.5     30  93.8 \n6     8     1     2  6.25    32 100   \n\nparms2&lt;-list(\n    list(mtcars,mtcars)\n    ,c(\"cyl\",\"cyl\")\n    ,c(\"gear\",\"am\")\n)\n\npmap(parms2,doit2)\n\n[[1]]\n# A tibble: 8 × 6\n    cyl  gear     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4     3     1  3.12     1   3.12\n2     4     4     8 25        9  28.1 \n3     4     5     2  6.25    11  34.4 \n4     6     3     2  6.25    13  40.6 \n5     6     4     4 12.5     17  53.1 \n6     6     5     1  3.12    18  56.2 \n7     8     3    12 37.5     30  93.8 \n8     8     5     2  6.25    32 100   \n\n[[2]]\n# A tibble: 6 × 6\n    cyl    am     n   pct  cumn cumpct\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1     4     0     3  9.38     3   9.38\n2     4     1     8 25       11  34.4 \n3     6     0     4 12.5     15  46.9 \n4     6     1     3  9.38    18  56.2 \n5     8     0    12 37.5     30  93.8 \n6     8     1     2  6.25    32 100   \n\n\n\n\nPython Version\nHere we combine 3 parameter lists into a single iterator object via zip—we can then map doit over parms via itertools.starmap.\n\nimport itertools as it\n\nparms=zip(\n    [mtcars,mtcars]\n    ,['cyl','cyl']\n    ,['gear','am']\n)\n\nlist(it.starmap(doit,parms))\n\nshape: (8, 6)\n┌─────┬──────┬─────┬───────┬──────┬────────┐\n│ cyl ┆ gear ┆ n   ┆ pct   ┆ cumn ┆ cumpct │\n│ --- ┆ ---  ┆ --- ┆ ---   ┆ ---  ┆ ---    │\n│ f64 ┆ f64  ┆ u32 ┆ f64   ┆ u32  ┆ f64    │\n╞═════╪══════╪═════╪═══════╪══════╪════════╡\n│ 4.0 ┆ 3.0  ┆ 1   ┆ 3.125 ┆ 1    ┆ 3.125  │\n│ 4.0 ┆ 4.0  ┆ 8   ┆ 25.0  ┆ 9    ┆ 28.125 │\n│ 4.0 ┆ 5.0  ┆ 2   ┆ 6.25  ┆ 11   ┆ 34.375 │\n│ 6.0 ┆ 3.0  ┆ 2   ┆ 6.25  ┆ 13   ┆ 40.625 │\n│ 6.0 ┆ 4.0  ┆ 4   ┆ 12.5  ┆ 17   ┆ 53.125 │\n│ 6.0 ┆ 5.0  ┆ 1   ┆ 3.125 ┆ 18   ┆ 56.25  │\n│ 8.0 ┆ 3.0  ┆ 12  ┆ 37.5  ┆ 30   ┆ 93.75  │\n│ 8.0 ┆ 5.0  ┆ 2   ┆ 6.25  ┆ 32   ┆ 100.0  │\n└─────┴──────┴─────┴───────┴──────┴────────┘\nshape: (6, 6)\n┌─────┬─────┬─────┬───────┬──────┬────────┐\n│ cyl ┆ am  ┆ n   ┆ pct   ┆ cumn ┆ cumpct │\n│ --- ┆ --- ┆ --- ┆ ---   ┆ ---  ┆ ---    │\n│ f64 ┆ f64 ┆ u32 ┆ f64   ┆ u32  ┆ f64    │\n╞═════╪═════╪═════╪═══════╪══════╪════════╡\n│ 4.0 ┆ 0.0 ┆ 3   ┆ 9.375 ┆ 3    ┆ 9.375  │\n│ 4.0 ┆ 1.0 ┆ 8   ┆ 25.0  ┆ 11   ┆ 34.375 │\n│ 6.0 ┆ 0.0 ┆ 4   ┆ 12.5  ┆ 15   ┆ 46.875 │\n│ 6.0 ┆ 1.0 ┆ 3   ┆ 9.375 ┆ 18   ┆ 56.25  │\n│ 8.0 ┆ 0.0 ┆ 12  ┆ 37.5  ┆ 30   ┆ 93.75  │\n│ 8.0 ┆ 1.0 ┆ 2   ┆ 6.25  ┆ 32   ┆ 100.0  │\n└─────┴─────┴─────┴───────┴──────┴────────┘\n[None, None]"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-9.-stack-data-frames-by-list-binding-with-map-and-anonymous-function",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-9.-stack-data-frames-by-list-binding-with-map-and-anonymous-function",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 9. Stack Data Frames by List Binding with Map and Anonymous Function",
    "text": "Example 9. Stack Data Frames by List Binding with Map and Anonymous Function\nWhat we’re achieving with this example—returning mtcars—isn’t very useful, but it illustrates a common task: mapping an anonymous function over a vector to create a list of data frames which are subsequently stacked together via row binding. In other words, in this example we’re reassembling mtcars by stacking together portions returned from each iteration of map.\n\nR Version\nPretty straight forward. Note that parms is a vector here.\n\nparms&lt;-distinct(mtcars,cyl) %&gt;%\n  pull()\n\nlist&lt;-map(\n  parms\n  ,function (x){\n    mtcars %&gt;%\n      dplyr::filter(cyl==x) %&gt;%\n      arrange(desc(mpg))\n  }\n)\n\ndf&lt;-list_rbind(list)\n\nprint(df)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n\n\n\nPython Version\nThis is extremely similar. Note that we’re pulling from the csv of mtcars to utilize eager evaluation (for simplicity).\n\nmtcars=pl.read_csv(\"mtcars.csv\")\n\niterator=mtcars.get_column(\"cyl\").unique()\n\ndf=map(\n    lambda x: (\n        mtcars\n        .filter(pl.col(\"cyl\")==x)\n        .sort(\"mpg\",descending=True)\n    )\n    ,iterator\n)\n\ndf=pl.concat(list(df))\n\nprint(df)\n\nshape: (32, 11)\n┌──────┬─────┬───────┬─────┬───┬─────┬─────┬──────┬──────┐\n│ mpg  ┆ cyl ┆ disp  ┆ hp  ┆ … ┆ vs  ┆ am  ┆ gear ┆ carb │\n│ ---  ┆ --- ┆ ---   ┆ --- ┆   ┆ --- ┆ --- ┆ ---  ┆ ---  │\n│ f64  ┆ i64 ┆ f64   ┆ i64 ┆   ┆ i64 ┆ i64 ┆ i64  ┆ i64  │\n╞══════╪═════╪═══════╪═════╪═══╪═════╪═════╪══════╪══════╡\n│ 33.9 ┆ 4   ┆ 71.1  ┆ 65  ┆ … ┆ 1   ┆ 1   ┆ 4    ┆ 1    │\n│ 32.4 ┆ 4   ┆ 78.7  ┆ 66  ┆ … ┆ 1   ┆ 1   ┆ 4    ┆ 1    │\n│ 30.4 ┆ 4   ┆ 75.7  ┆ 52  ┆ … ┆ 1   ┆ 1   ┆ 4    ┆ 2    │\n│ 30.4 ┆ 4   ┆ 95.1  ┆ 113 ┆ … ┆ 1   ┆ 1   ┆ 5    ┆ 2    │\n│ 27.3 ┆ 4   ┆ 79.0  ┆ 66  ┆ … ┆ 1   ┆ 1   ┆ 4    ┆ 1    │\n│ …    ┆ …   ┆ …     ┆ …   ┆ … ┆ …   ┆ …   ┆ …    ┆ …    │\n│ 14.7 ┆ 8   ┆ 440.0 ┆ 230 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 4    │\n│ 14.3 ┆ 8   ┆ 360.0 ┆ 245 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 4    │\n│ 13.3 ┆ 8   ┆ 350.0 ┆ 245 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 4    │\n│ 10.4 ┆ 8   ┆ 472.0 ┆ 205 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 4    │\n│ 10.4 ┆ 8   ┆ 460.0 ┆ 215 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 4    │\n└──────┴─────┴───────┴─────┴───┴─────┴─────┴──────┴──────┘"
  },
  {
    "objectID": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-10.-stack-data-frames-by-list-binding-with-pmap-and-anonymous-function-of-dots-...",
    "href": "posts/2025-03-19-TidyR-to-PolarsPython/index.html#example-10.-stack-data-frames-by-list-binding-with-pmap-and-anonymous-function-of-dots-...",
    "title": "Recreating Some Tidy-Style R Operations with Python and Polars",
    "section": "Example 10. Stack Data Frames by List Binding with pmap and Anonymous Function of Dots (...)",
    "text": "Example 10. Stack Data Frames by List Binding with pmap and Anonymous Function of Dots (...)\nThis example generalizes the previous one to use a data frame with any number of columns (here we’re just using 2) to parameterize the mapping.\n\nR Version\nDynamic dots are captured in the list parms within the function and column values are referenced as elements of that list.\n\nparms&lt;-distinct(mtcars,cyl,gear)\n\nlist&lt;-pmap(\n  parms\n  ,function (...){\n    parms&lt;-rlang::dots_list(...)\n    mtcars %&gt;%\n      dplyr::filter(cyl==parms$cyl & gear==parms$gear) \n  }\n)\n\ndf&lt;-list_rbind(list)\n\nprint(df)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n\n\n\n\nPython Version\nThis is very similar to the R version above. The key is that each row of the data frame parms is turned into a dictionary (i.e., has the form {'key1':_key1val_,...,'keyk':_keykval_}). iterator is then a list of dictionaries (iter_rows() returns dictionaries when named=True) which allows us to capture a single row of all parameters needed in the body of the anonymous function with the single parameter dctnry. The parameter values can be referenced by the original parms data frame variable name in the function body via the dictionary method get(). Note that there is a Polars DataFrame method map_rows() that does something similar, but there’s no way to preserve variable names for reference inside the function, so this approach seems preferrable.\n\nmtcars=pl.read_csv(\"mtcars.csv\")\n\nparms=(\n    mtcars\n    .group_by(\"cyl\",\"gear\")\n    .agg()\n)\n\niterator=list(parms.iter_rows(named=True))\n\ndfs=map(\n    lambda dctnry: (\n        mtcars\n        .filter(\n            (pl.col(\"cyl\")==dctnry.get('cyl')) & \n            (pl.col(\"gear\")==dctnry.get('gear'))\n        )\n    )\n    ,iterator\n)\n\ndf=pl.concat(list(dfs))\n\nprint(df)\n\nshape: (32, 11)\n┌──────┬─────┬───────┬─────┬───┬─────┬─────┬──────┬──────┐\n│ mpg  ┆ cyl ┆ disp  ┆ hp  ┆ … ┆ vs  ┆ am  ┆ gear ┆ carb │\n│ ---  ┆ --- ┆ ---   ┆ --- ┆   ┆ --- ┆ --- ┆ ---  ┆ ---  │\n│ f64  ┆ i64 ┆ f64   ┆ i64 ┆   ┆ i64 ┆ i64 ┆ i64  ┆ i64  │\n╞══════╪═════╪═══════╪═════╪═══╪═════╪═════╪══════╪══════╡\n│ 18.7 ┆ 8   ┆ 360.0 ┆ 175 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 2    │\n│ 14.3 ┆ 8   ┆ 360.0 ┆ 245 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 4    │\n│ 16.4 ┆ 8   ┆ 275.8 ┆ 180 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 3    │\n│ 17.3 ┆ 8   ┆ 275.8 ┆ 180 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 3    │\n│ 15.2 ┆ 8   ┆ 275.8 ┆ 180 ┆ … ┆ 0   ┆ 0   ┆ 3    ┆ 3    │\n│ …    ┆ …   ┆ …     ┆ …   ┆ … ┆ …   ┆ …   ┆ …    ┆ …    │\n│ 21.4 ┆ 6   ┆ 258.0 ┆ 110 ┆ … ┆ 1   ┆ 0   ┆ 3    ┆ 1    │\n│ 18.1 ┆ 6   ┆ 225.0 ┆ 105 ┆ … ┆ 1   ┆ 0   ┆ 3    ┆ 1    │\n│ 15.8 ┆ 8   ┆ 351.0 ┆ 264 ┆ … ┆ 0   ┆ 1   ┆ 5    ┆ 4    │\n│ 15.0 ┆ 8   ┆ 301.0 ┆ 335 ┆ … ┆ 0   ┆ 1   ┆ 5    ┆ 8    │\n│ 21.5 ┆ 4   ┆ 120.1 ┆ 97  ┆ … ┆ 1   ┆ 0   ┆ 3    ┆ 1    │\n└──────┴─────┴───────┴─────┴───┴─────┴─────┴──────┴──────┘"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]